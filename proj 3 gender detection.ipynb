{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1698647617631,"user":{"displayName":"Samruddhi Chalke","userId":"10331284242762889250"},"user_tz":-330},"id":"z94GVpdgmbZz"},"outputs":[],"source":["\n","from keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Activation\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Dense\n","from tensorflow.keras import datasets, layers, models\n","from keras import backend as K\n","from keras import models\n","from keras.applications.vgg16 import VGG16"]},{"cell_type":"markdown","metadata":{"id":"7VymXLjYoeDW"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLwedq3AmoSt"},"outputs":[],"source":["class SmallerVGGNet:\n","    @staticmethod\n","    def vgg_net(width, height, depth, classes):\n","            conv_base = VGG16(weights='imagenet',\n","                          include_top=False,\n","                          input_shape=(height, width, depth))\n","            model = models.Sequential()\n","\n","            model.add(conv_base)\n","            model.add(Flatten())\n","            model.add(Dense(1024, activation='relu'))\n","            model.add(BatchNormalization())\n","            model.add(Dropout(0.5))\n","            model.add(Dense(classes, activation='sigmoid'))\n","            return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnSXYlVgoEbN"},"outputs":[],"source":["import matplotlib\n","matplotlib.use(\"Agg\")\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers.legacy import Adam, SGD, RMSprop\n","from tensorflow.keras.utils import img_to_array\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.utils import plot_model\n","from sklearn.model_selection import train_test_split\n","# from model.smallervggnet import SmallerVGGNet\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import random\n","import cv2\n","import os\n","import glob\n","from keras.callbacks import *\n","from keras.models import load_model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275510,"status":"ok","timestamp":1698647617626,"user":{"displayName":"Samruddhi Chalke","userId":"10331284242762889250"},"user_tz":-330},"id":"7wKk0N5WnXDk","outputId":"e4a65f0f-526a-4e41-ae6a-c6de54b4a667"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n","\u003cipython-input-9-3a5a0d76671e\u003e:66: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","92/92 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.6597\n","Epoch 1: val_accuracy improved from -inf to 0.48583, saving model to epochs:001-val_accuracy:0.486.hdf5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["92/92 [==============================] - 28s 158ms/step - loss: 0.6766 - accuracy: 0.6597 - val_loss: 1.8234 - val_accuracy: 0.4858\n","Epoch 2/50\n","92/92 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7618\n","Epoch 2: val_accuracy did not improve from 0.48583\n","92/92 [==============================] - 12s 127ms/step - loss: 0.5309 - accuracy: 0.7618 - val_loss: 46.6377 - val_accuracy: 0.4818\n","Epoch 3/50\n","92/92 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.7713\n","Epoch 3: val_accuracy improved from 0.48583 to 0.63563, saving model to epochs:003-val_accuracy:0.636.hdf5\n","92/92 [==============================] - 12s 133ms/step - loss: 0.4952 - accuracy: 0.7713 - val_loss: 9.8178 - val_accuracy: 0.6356\n","Epoch 4/50\n","92/92 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.7898\n","Epoch 4: val_accuracy did not improve from 0.63563\n","92/92 [==============================] - 12s 127ms/step - loss: 0.4711 - accuracy: 0.7898 - val_loss: 809.0500 - val_accuracy: 0.5803\n","Epoch 5/50\n","92/92 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.8113\n","Epoch 5: val_accuracy improved from 0.63563 to 0.65317, saving model to epochs:005-val_accuracy:0.653.hdf5\n","92/92 [==============================] - 11s 118ms/step - loss: 0.4422 - accuracy: 0.8113 - val_loss: 383.6252 - val_accuracy: 0.6532\n","Epoch 6/50\n","92/92 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8174\n","Epoch 6: val_accuracy did not improve from 0.65317\n","92/92 [==============================] - 11s 116ms/step - loss: 0.4246 - accuracy: 0.8174 - val_loss: 12.6822 - val_accuracy: 0.5155\n","Epoch 7/50\n","92/92 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8235\n","Epoch 7: val_accuracy improved from 0.65317 to 0.87179, saving model to epochs:007-val_accuracy:0.872.hdf5\n","92/92 [==============================] - 12s 129ms/step - loss: 0.4088 - accuracy: 0.8235 - val_loss: 0.3152 - val_accuracy: 0.8718\n","Epoch 8/50\n","92/92 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8488\n","Epoch 8: val_accuracy improved from 0.87179 to 0.90148, saving model to epochs:008-val_accuracy:0.901.hdf5\n","92/92 [==============================] - 12s 130ms/step - loss: 0.3588 - accuracy: 0.8488 - val_loss: 0.2566 - val_accuracy: 0.9015\n","Epoch 9/50\n","92/92 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8584\n","Epoch 9: val_accuracy improved from 0.90148 to 0.90418, saving model to epochs:009-val_accuracy:0.904.hdf5\n","92/92 [==============================] - 12s 128ms/step - loss: 0.3265 - accuracy: 0.8584 - val_loss: 0.2755 - val_accuracy: 0.9042\n","Epoch 10/50\n","92/92 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8676\n","Epoch 10: val_accuracy did not improve from 0.90418\n","92/92 [==============================] - 11s 118ms/step - loss: 0.3165 - accuracy: 0.8676 - val_loss: 0.2721 - val_accuracy: 0.8920\n","Epoch 11/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.8867\n","Epoch 11: val_accuracy improved from 0.90418 to 0.91903, saving model to epochs:011-val_accuracy:0.919.hdf5\n","92/92 [==============================] - 12s 129ms/step - loss: 0.2775 - accuracy: 0.8867 - val_loss: 0.2091 - val_accuracy: 0.9190\n","Epoch 12/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.8833\n","Epoch 12: val_accuracy did not improve from 0.91903\n","92/92 [==============================] - 11s 124ms/step - loss: 0.2929 - accuracy: 0.8833 - val_loss: 0.2360 - val_accuracy: 0.9028\n","Epoch 13/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.8980\n","Epoch 13: val_accuracy improved from 0.91903 to 0.92982, saving model to epochs:013-val_accuracy:0.930.hdf5\n","92/92 [==============================] - 12s 130ms/step - loss: 0.2572 - accuracy: 0.8980 - val_loss: 0.1876 - val_accuracy: 0.9298\n","Epoch 14/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.8983\n","Epoch 14: val_accuracy did not improve from 0.92982\n","92/92 [==============================] - 11s 118ms/step - loss: 0.2554 - accuracy: 0.8983 - val_loss: 0.2559 - val_accuracy: 0.9109\n","Epoch 15/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.9000\n","Epoch 15: val_accuracy did not improve from 0.92982\n","92/92 [==============================] - 10s 113ms/step - loss: 0.2432 - accuracy: 0.9000 - val_loss: 0.2415 - val_accuracy: 0.9123\n","Epoch 16/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.9096\n","Epoch 16: val_accuracy improved from 0.92982 to 0.93387, saving model to epochs:016-val_accuracy:0.934.hdf5\n","92/92 [==============================] - 12s 129ms/step - loss: 0.2356 - accuracy: 0.9096 - val_loss: 0.1756 - val_accuracy: 0.9339\n","Epoch 17/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9177\n","Epoch 17: val_accuracy did not improve from 0.93387\n","92/92 [==============================] - 11s 123ms/step - loss: 0.2113 - accuracy: 0.9177 - val_loss: 0.1952 - val_accuracy: 0.9298\n","Epoch 18/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.9201\n","Epoch 18: val_accuracy improved from 0.93387 to 0.93522, saving model to epochs:018-val_accuracy:0.935.hdf5\n","92/92 [==============================] - 12s 130ms/step - loss: 0.2105 - accuracy: 0.9201 - val_loss: 0.1604 - val_accuracy: 0.9352\n","Epoch 19/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9212\n","Epoch 19: val_accuracy improved from 0.93522 to 0.94197, saving model to epochs:019-val_accuracy:0.942.hdf5\n","92/92 [==============================] - 12s 130ms/step - loss: 0.1974 - accuracy: 0.9212 - val_loss: 0.1501 - val_accuracy: 0.9420\n","Epoch 20/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9144\n","Epoch 20: val_accuracy did not improve from 0.94197\n","92/92 [==============================] - 10s 110ms/step - loss: 0.2107 - accuracy: 0.9144 - val_loss: 0.1668 - val_accuracy: 0.9420\n","Epoch 21/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9307\n","Epoch 21: val_accuracy did not improve from 0.94197\n","92/92 [==============================] - 11s 121ms/step - loss: 0.1773 - accuracy: 0.9307 - val_loss: 0.5605 - val_accuracy: 0.8556\n","Epoch 22/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9276\n","Epoch 22: val_accuracy improved from 0.94197 to 0.95682, saving model to epochs:022-val_accuracy:0.957.hdf5\n","92/92 [==============================] - 12s 131ms/step - loss: 0.1887 - accuracy: 0.9276 - val_loss: 0.5346 - val_accuracy: 0.9568\n","Epoch 23/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9283\n","Epoch 23: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1802 - accuracy: 0.9283 - val_loss: 134.9699 - val_accuracy: 0.9285\n","Epoch 24/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9341\n","Epoch 24: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 125ms/step - loss: 0.1664 - accuracy: 0.9341 - val_loss: 0.1686 - val_accuracy: 0.9460\n","Epoch 25/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9218\n","Epoch 25: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 10s 110ms/step - loss: 0.1969 - accuracy: 0.9218 - val_loss: 0.1609 - val_accuracy: 0.9271\n","Epoch 26/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9331\n","Epoch 26: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 120ms/step - loss: 0.1759 - accuracy: 0.9331 - val_loss: 0.1718 - val_accuracy: 0.9460\n","Epoch 27/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9423\n","Epoch 27: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1448 - accuracy: 0.9423 - val_loss: 0.1777 - val_accuracy: 0.9298\n","Epoch 28/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9355\n","Epoch 28: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1554 - accuracy: 0.9355 - val_loss: 0.1218 - val_accuracy: 0.9555\n","Epoch 29/50\n","92/92 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8543\n","Epoch 29: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 121ms/step - loss: 0.3657 - accuracy: 0.8543 - val_loss: 1.4761 - val_accuracy: 0.7935\n","Epoch 30/50\n","92/92 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.8543\n","Epoch 30: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 10s 110ms/step - loss: 0.3418 - accuracy: 0.8543 - val_loss: 20.0953 - val_accuracy: 0.9109\n","Epoch 31/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.8870\n","Epoch 31: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 120ms/step - loss: 0.2777 - accuracy: 0.8870 - val_loss: 0.2201 - val_accuracy: 0.8974\n","Epoch 32/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9085\n","Epoch 32: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 122ms/step - loss: 0.2362 - accuracy: 0.9085 - val_loss: 0.1836 - val_accuracy: 0.9244\n","Epoch 33/50\n","92/92 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9184\n","Epoch 33: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 123ms/step - loss: 0.2034 - accuracy: 0.9184 - val_loss: 0.1554 - val_accuracy: 0.9379\n","Epoch 34/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9222\n","Epoch 34: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 121ms/step - loss: 0.1919 - accuracy: 0.9222 - val_loss: 0.1480 - val_accuracy: 0.9285\n","Epoch 35/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9304\n","Epoch 35: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 12s 125ms/step - loss: 0.1794 - accuracy: 0.9304 - val_loss: 0.1473 - val_accuracy: 0.9474\n","Epoch 36/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9334\n","Epoch 36: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1693 - accuracy: 0.9334 - val_loss: 0.1188 - val_accuracy: 0.9514\n","Epoch 37/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9382\n","Epoch 37: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 124ms/step - loss: 0.1571 - accuracy: 0.9382 - val_loss: 0.1201 - val_accuracy: 0.9555\n","Epoch 38/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9427\n","Epoch 38: val_accuracy did not improve from 0.95682\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1506 - accuracy: 0.9427 - val_loss: 0.1630 - val_accuracy: 0.9379\n","Epoch 39/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9338\n","Epoch 39: val_accuracy improved from 0.95682 to 0.96221, saving model to epochs:039-val_accuracy:0.962.hdf5\n","92/92 [==============================] - 12s 131ms/step - loss: 0.1626 - accuracy: 0.9338 - val_loss: 0.1083 - val_accuracy: 0.9622\n","Epoch 40/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9416\n","Epoch 40: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1482 - accuracy: 0.9416 - val_loss: 0.1377 - val_accuracy: 0.9474\n","Epoch 41/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9406\n","Epoch 41: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 122ms/step - loss: 0.1525 - accuracy: 0.9406 - val_loss: 0.1485 - val_accuracy: 0.9501\n","Epoch 42/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9488\n","Epoch 42: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 10s 112ms/step - loss: 0.1354 - accuracy: 0.9488 - val_loss: 0.1444 - val_accuracy: 0.9447\n","Epoch 43/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9546\n","Epoch 43: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 121ms/step - loss: 0.1300 - accuracy: 0.9546 - val_loss: 0.1081 - val_accuracy: 0.9555\n","Epoch 44/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9481\n","Epoch 44: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 124ms/step - loss: 0.1383 - accuracy: 0.9481 - val_loss: 0.1452 - val_accuracy: 0.9555\n","Epoch 45/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9485\n","Epoch 45: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1247 - accuracy: 0.9485 - val_loss: 0.1223 - val_accuracy: 0.9555\n","Epoch 46/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9553\n","Epoch 46: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 123ms/step - loss: 0.1222 - accuracy: 0.9553 - val_loss: 0.1256 - val_accuracy: 0.9595\n","Epoch 47/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9474\n","Epoch 47: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 10s 112ms/step - loss: 0.1243 - accuracy: 0.9474 - val_loss: 0.1026 - val_accuracy: 0.9622\n","Epoch 48/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9502\n","Epoch 48: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 124ms/step - loss: 0.1241 - accuracy: 0.9502 - val_loss: 0.1442 - val_accuracy: 0.9487\n","Epoch 49/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9553\n","Epoch 49: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 124ms/step - loss: 0.1117 - accuracy: 0.9553 - val_loss: 0.1086 - val_accuracy: 0.9622\n","Epoch 50/50\n","92/92 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9549\n","Epoch 50: val_accuracy did not improve from 0.96221\n","92/92 [==============================] - 11s 121ms/step - loss: 0.1211 - accuracy: 0.9549 - val_loss: 0.1418 - val_accuracy: 0.9501\n"]}],"source":["import glob\n","import os\n","import random\n","epochs = 50\n","lr = 1e-3\n","batch_size = 32\n","img_dims = (96,96,3)\n","\n","data = []\n","labels = []\n","\n","# load image files from the dataset\n","image_files = [f for f in glob.glob('/content/drive/MyDrive/gender_dataset_face-20220319T023558Z-001' + \"/**/*\", recursive=True)\n","if not os.path.isdir(f)]\n","random.seed(42)\n","random.shuffle(image_files)\n","\n","# create groud-truth label from the image path\n","for img in image_files:\n","\n","    image = cv2.imread(img)\n","    # print(img)\n","    image = cv2.resize(image, (96,96))\n","    image = img_to_array(image)\n","    data.append(image)\n","\n","    label = img.split(os.path.sep)[-2]\n","    if label == \"woman\":\n","        label = 1\n","    else:\n","        label = 0\n","\n","    labels.append([label])\n","\n","# pre-processing\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","# split dataset for training and validation\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2,\n","                                                  random_state=2)\n","trainY = to_categorical(trainY, num_classes=2)\n","testY = to_categorical(testY, num_classes=2)\n","\n","# augmenting datset\n","aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n","                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","                         horizontal_flip=True, fill_mode=\"nearest\")\n","\n","# build model\n","# model = SmallerVGGNet.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n","#                             classes=2)\n","model = SmallerVGGNet.vgg_net(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n","                            classes=2)\n","\n","# compile the model\n","opt = Adam(lr=lr, decay=lr/epochs)\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","#checkpoint save\n","filepath=\"epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","# model.load_model(\"Model_weights/epochs:009-val_accuracy:0.797.hdf5\")\n","\n","# train the model\n","history = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n","                        validation_data=(testX,testY),\n","                        steps_per_epoch=len(trainX) // batch_size,\n","                        epochs=epochs, verbose=1,callbacks=callbacks_list)\n","# model.load_weights(\"Model_weights/epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.hdf5\")\n","\n","# save the model to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7lf0hTbYUgVY"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHoykW2tnn3G"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","# plt.savefig('/content/drive/My Drive/Interface_model/result.plot')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"_CIJV44syhrv"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2218,"status":"ok","timestamp":1698647636359,"user":{"displayName":"Samruddhi Chalke","userId":"10331284242762889250"},"user_tz":-330},"id":"ymqKlitRpQFt","outputId":"eb71d5a6-d3c7-443d-9160-be64517fcdf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["24/24 [==============================] - 1s 26ms/step\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","pred = model.predict(testX)\n","pred = np.argmax(pred,axis = 1)\n","y_true = np.argmax(testY,axis = 1)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"executionInfo":{"elapsed":2461,"status":"ok","timestamp":1698647645688,"user":{"displayName":"Samruddhi Chalke","userId":"10331284242762889250"},"user_tz":-330},"id":"63kb2nK_pTUG","outputId":"e237a035-ab21-48fb-d70f-5536f56073fb"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 500x500 with 1 Axes\u003e"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["CM = confusion_matrix(y_true, pred)\n","from mlxtend.plotting import plot_confusion_matrix\n","fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n","# plt.show()\n","fig"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11381,"status":"ok","timestamp":1698642016842,"user":{"displayName":"Samruddhi Chalke","userId":"10331284242762889250"},"user_tz":-330},"id":"hVZvSg1xpayp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting cvlib\n","  Downloading cvlib-0.2.7.tar.gz (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cvlib) (1.23.5)\n","Collecting progressbar (from cvlib)\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cvlib) (2.31.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cvlib) (9.4.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from cvlib) (2.31.6)\n","Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (from cvlib) (0.5.4)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ecvlib) (3.3.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ecvlib) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ecvlib) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ecvlib) (2023.7.22)\n","Building wheels for collected packages: cvlib, progressbar\n","  Building wheel for cvlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cvlib: filename=cvlib-0.2.7-py3-none-any.whl size=10046367 sha256=68e725e5dc5e865cb4ac575aa44d24dbdeb89064102308cf1ad31e35f1310195\n","  Stored in directory: /root/.cache/pip/wheels/9e/a5/d4/fe37b48fe4f4b621ba5e574a991230070f3cc4f02322a01489\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=a91a4f24e47df2db38741016a0dfc031b3d8bd8cf5c7b425dfd18e4feb500573\n","  Stored in directory: /root/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n","Successfully built cvlib progressbar\n","Installing collected packages: progressbar, cvlib\n","Successfully installed cvlib-0.2.7 progressbar-2.5\n"]}],"source":["!pip install cvlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3pmgQeypXct"},"outputs":[],"source":["# from keras.preprocessing.image import img_to_array\n","from tensorflow.keras.utils import img_to_array\n","\n","from keras.models import load_model\n","# from keras.utils import get_file\n","import numpy as np\n","import argparse\n","import cv2\n","import os\n","import cvlib as cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4k8_2RNyrDtb"},"outputs":[],"source":["img= '/content/drive/MyDrive/menty.jpg'\n","image = cv2.imread(img)\n","# cv2.imread('/conte')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2688,"status":"ok","timestamp":1698642056926,"user":{"displayName":"Samruddhi Chalke","userId":"10331284242762889250"},"user_tz":-330},"id":"ZBpE52ruM1No","outputId":"d9c1b43c-3ac5-4749-928f-2f7a334c208d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 575ms/step\n","[0.00685085 0.9929765 ]\n","['man', 'woman']\n"]},{"data":{"text/plain":["True"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["image = cv2.imread('/content/drive/MyDrive/Picsart_23-04-11_20-49-29-294.png')\n","\n","if image is None:\n","    print(\"Could not read input image\")\n","    exit()\n","\n","# load pre-trained model\n","model = load_model(\"/content/epochs:044-val_accuracy:0.969.hdf5\")\n","\n","# detect faces in the image\n","face, confidence = cv.detect_face(image)\n","\n","classes = ['man','woman']\n","# loop through detected faces\n","for idx, f in enumerate(face):\n","\n","     # get corner points of face rectangle\n","    (startX, startY) = f[0], f[1]\n","    (endX, endY) = f[2], f[3]\n","\n","    # draw rectangle over face\n","    cv2.rectangle(image, (startX,startY), (endX,endY), (0,255,0), 2)\n","\n","    # crop the detected face region\n","    face_crop = np.copy(image[startY:endY,startX:endX])\n","\n","    # preprocessing for gender detection model\n","    face_crop = cv2.resize(face_crop,(96,96))\n","    face_crop = face_crop.astype(\"float\") / 255.0\n","    face_crop = img_to_array(face_crop)\n","    face_crop = np.expand_dims(face_crop, axis=0)\n","\n","    # apply gender detection on face\n","    conf = model.predict(face_crop)[0]\n","    print(conf)\n","    print(classes)\n","\n","    # get label with max accuracy\n","    idx = np.argmax(conf)\n","    label = classes[idx]\n","\n","    label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\n","\n","    Y = startY - 10 if startY - 10 \u003e 10 else startY + 10\n","\n","    # write label and confidence above face rectangle\n","    if conf[idx] * 100 \u003e 50.0:\n","        cv2.putText(image, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n","                0.7, (0, 255, 0), 1)\n","# cv2.imwrite('/content/',image)\n","# display output\n","# cv2.imshow(\"gender detection\", image)\n","\n","# # press any key to close window\n","# cv2.waitKey(0)\n","\n","# # save output\n","cv2.imwrite(\"gender_detection.jpg\", image)\n","\n","# # release resources\n","# cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"pSiZR2x6ql7N"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0jq3UY55V7K"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UER7TaOvQw07"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
